import streamlit as st
import pandas as pd
import feedparser
import urllib.parse
from datetime import datetime
import time
from duckduckgo_search import DDGS
from pytrends.request import TrendReq

# --- 1. é é¢è¨­å®š (å¿…é ˆæ”¾åœ¨ç¬¬ä¸€è¡Œ) ---
st.set_page_config(page_title="å…¨çƒå»šé›»æƒ…å ±ä¸­å¿ƒ", page_icon="ğŸ³", layout="wide")

# --- 2. Session State åˆå§‹åŒ– ---
if 'favorites' not in st.session_state:
    st.session_state.favorites = pd.DataFrame(columns=['Folder', 'Date', 'Title', 'Link', 'Source'])

if 'folder_list' not in st.session_state:
    st.session_state.folder_list = ["ğŸ“¥ æœªåˆ†é¡", "ğŸ”¥ æ–¹å¤ª (Fotile)", "ğŸ”¥ è€é—† (Robam)", "ğŸ‡ªğŸ‡º æ­ç³»å“ç‰Œ", "ğŸ‡ºğŸ‡¸ ç¾ç³»å“ç‰Œ"]

if 'search_results' not in st.session_state:
    st.session_state.search_results = pd.DataFrame()

# --- 3. çˆ¬èŸ²å‡½æ•¸ç¾¤ ---

# A. Google News
def fetch_google_news(keyword, lang, region):
    search_query = keyword
    target_gl = region
    try:
        target_ceid = f"{region}:{lang.split('-')[0]}"
    except:
        target_ceid = f"{region}:en"

    if (region in ["US", "CA"]) and ("zh" in lang):
        if region == "US": search_query = f"{keyword} (ç¾åœ‹ OR åŒ—ç¾ OR USA)"
        elif region == "CA": search_query = f"{keyword} (åŠ æ‹¿å¤§ OR Canada OR æ¸©å“¥å OR å¤šä¼¦å¤š)"
        target_gl = "TW"
        target_ceid = "TW:zh-Hant"

    if region == "HK" and "zh" in lang:
        target_ceid = "HK:zh-Hant"
        target_gl = "HK"

    encoded_keyword = urllib.parse.quote(search_query)
    target_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl={lang}&gl={target_gl}&ceid={target_ceid}"
    
    try:
        feed = feedparser.parse(target_url)
        data = []
        if feed.entries:
            for entry in feed.entries:
                try: pub_date = datetime(*entry.published_parsed[:6])
                except: pub_date = datetime.now()
                data.append({
                    "Select": False,
                    "Date": pub_date,
                    "Type": "ğŸ“° æ–°è",
                    "Title": entry.title,
                    "Source": entry.source.title if 'source' in entry else "Google News",
                    "Link": entry.link
                })
            return pd.DataFrame(data)
        else:
            return pd.DataFrame()
    except Exception as e:
        return pd.DataFrame()

# B. DuckDuckGo
def fetch_web_search(keyword, region_code, time_range, platform_mode=None):
    if region_code == "US": ddg_region = "us-en"
    elif region_code == "CA": ddg_region = "ca-en"
    elif region_code == "HK": ddg_region = "hk-tzh"
    else: ddg_region = "wt-wt"
    
    ddg_time = None 
    if time_range == "éå»ä¸€å¤©": ddg_time = "d"
    elif time_range == "éå»ä¸€é€±": ddg_time = "w"
    elif time_range == "éå»ä¸€å€‹æœˆ": ddg_time = "m"
    elif time_range == "éå»ä¸€å¹´": ddg_time = "y"
    
    final_keyword = keyword
    search_region = ddg_region
    source_type = "ğŸŒ å…¨ç¶²"

    if platform_mode == "reddit":
        final_keyword = f"{keyword} site:reddit.com"
        source_type = "ğŸ’¬ Reddit"
    elif platform_mode == "pinterest":
        final_keyword = f"{keyword} site:pinterest.com"
        source_type = "ğŸ“Œ Pinterest"
    elif platform_mode == "shopping":
        final_keyword = f"buy {keyword} online price"
        source_type = "ğŸ’° åƒ¹æ ¼æƒ…å ±"
    else:
        source_type = "ğŸŒ è«–å£‡/éƒ¨è½æ ¼"
        is_chinese_query = any(u'\u4e00' <= c <= u'\u9fff' for c in keyword)
        if (region_code in ["US", "CA"]) and is_chinese_query:
            search_region = "wt-wt"
            if region_code == "US": final_keyword = f"{keyword} (ç¾åœ‹ OR åŒ—ç¾ OR è¯äºº)"
            elif region_code == "CA": final_keyword = f"{keyword} (åŠ æ‹¿å¤§ OR æ¸©å“¥è¯ OR å¤šå€«å¤š)"

    try:
        results = DDGS().text(keywords=final_keyword, region=search_region, time=ddg_time, max_results=30)
        data = []
        if results:
            for r in results:
                link = r.get('href', '')
                title = r.get('title', '')
                if link and title:
                    try: source_domain = urllib.parse.urlparse(link).netloc
                    except: source_domain = "Web"
                    data.append({
                        "Select": False,
                        "Date": datetime.now(),
                        "Type": source_type,
                        "Title": title,
                        "Source": source_domain,
                        "Link": link
                    })
        return pd.DataFrame(data)
    except Exception as e:
        return pd.DataFrame()

# C. æ··åˆæœç´¢
def run_hybrid_search(keyword, location_choice, search_types, time_range):
    frames = []
    
    # åœ°å€è¨­å®š
    if location_choice == "ğŸ‡ºğŸ‡¸ ç¾åœ‹ (US)":
        news_tasks = [("en-US", "US"), ("zh-TW", "US")]
        region_code = "US"
    elif location_choice == "ğŸ‡¨ğŸ‡¦ åŠ æ‹¿å¤§ (CA)":
        news_tasks = [("en-CA", "CA"), ("zh-TW", "CA")]
        region_code = "CA"
    elif location_choice == "ğŸ‡­ğŸ‡° é¦™æ¸¯ (HK)":
        news_tasks = [("zh-HK", "HK"), ("en-HK", "HK")]
        region_code = "HK"
    
    if "æ–°èåª’é«” (News)" in search_types:
        if time_range in ["ä¸é™æ™‚é–“ (é è¨­)", "éå»ä¸€å¤©", "éå»ä¸€é€±", "éå»ä¸€å€‹æœˆ"]:
            for lang, region in news_tasks:
                df = fetch_google_news(keyword, lang, region)
                if not df.empty: frames.append(df)
            
    if "è«–å£‡èˆ‡éƒ¨è½æ ¼ (Web/Blogs)" in search_types:
        df = fetch_web_search(keyword, region_code, time_range, platform_mode=None)
        if not df.empty: frames.append(df)

    if "Reddit è¨è«–å€" in search_types:
        df = fetch_web_search(keyword, region_code, time_range, platform_mode="reddit")
        if not df.empty: frames.append(df)
        
    if "Pinterest éˆæ„Ÿ" in search_types:
        df = fetch_web_search(keyword, region_code, time_range, platform_mode="pinterest")
        if not df.empty: frames.append(df)

    if frames:
        result = pd.concat(frames)
        if 'Select' not in result.columns:
            result['Select'] = False
        result = result.drop_duplicates(subset=['Link'])
        return result
    else:
        return pd.DataFrame(columns=['Select', 'Type', 'Date', 'Title', 'Link', 'Source'])

# D. Google Trends
def fetch_trends_data(keywords, geo='US', timeframe='today 12-m'):
    try:
        pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25))
        pytrends.build_payload(keywords, cat=0, timeframe=timeframe, geo=geo)
        interest_over_time_df = pytrends.interest_over_time()
        if not interest_over_time_df.empty and 'isPartial' in interest_over_time_df.columns:
            interest_over_time_df = interest_over_time_df.drop(columns=['isPartial'])
        related_queries = pytrends.related_queries()
        related_df = pd.DataFrame()
        if related_queries and keywords[0] in related_queries and related_queries[keywords[0]]['top'] is not None:
            related_df = related_queries[keywords[0]]['top'].head(10)
        return interest_over_time_df, related_df
    except Exception as e:
        return pd.DataFrame(), pd.DataFrame()

# --- 4. å´é‚Šæ¬„å°èˆª ---
with st.sidebar:
    st.title("ğŸ—‚ï¸ ç³»çµ±å°èˆª")
    page = st.radio("å‰å¾€å°ˆå€", ["ğŸ” æƒ…å ±æœå°‹", "ğŸ“ˆ è¶¨å‹¢åˆ†æå„€", "ğŸ’° ç«¶å“æ¯”åƒ¹ä¸­å¿ƒ", "ğŸ“‚ ç«¶å“è³‡æ–™å¤¾"])
    st.divider()
    
    st.subheader("âš™ï¸ è³‡æ–™å¤¾ç®¡ç†")
    new_folder = st.text_input("æ–°å¢è³‡æ–™å¤¾", placeholder="ä¾‹å¦‚: Pinterest éˆæ„Ÿæ¿")
    if st.button("â• æ–°å¢"):
        if new_folder and new_folder not in st.session_state.folder_list:
            st.session_state.folder_list.append(new_folder)
            st.success(f"å·²æ–°å¢: {new_folder}")
            st.rerun()
    st.caption(f"å·²æ”¶è—: {len(st.session_state.favorites)} ç­†")

# --- 5. é é¢é‚è¼¯ ---

# === PAGE 1: æƒ…å ±æœå°‹ ===
if page == "ğŸ” æƒ…å ±æœå°‹":
    st.title("ğŸ” æƒ…å ±æœå°‹")
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1: search_kw = st.text_input("è¼¸å…¥é—œéµå­— (å¯å¤šå€‹)", placeholder="ä¾‹å¦‚: Fotile, Robam, Review...")
    with col2: location = st.selectbox("ç›®æ¨™å¸‚å ´", ["ğŸ‡ºğŸ‡¸ ç¾åœ‹ (US)", "ğŸ‡¨ğŸ‡¦ åŠ æ‹¿å¤§ (CA)", "ğŸ‡­ğŸ‡° é¦™æ¸¯ (HK)"])
    with col3: time_range = st.selectbox("æ™‚é–“ç¯„åœ", ["ä¸é™æ™‚é–“ (é è¨­)", "éå»ä¸€å¤©", "éå»ä¸€é€±", "éå»ä¸€å€‹æœˆ", "éå»ä¸€å¹´"])
    
    st.markdown("---")
    col_logic, col_scope = st.columns([1, 2])
    with col_logic:
        search_logic = st.radio("ğŸ”— é—œéµå­—é‚è¼¯", ["ğŸ”„ å€‹åˆ¥åˆ†é–‹æœ (Loop)", "ğŸ”€ è¯é›†æœå°‹ (OR)", "â• äº¤é›†æœå°‹ (AND)"])
    with col_scope:
        search_scope = st.multiselect("é¸æ“‡æœå°‹é »é“", ["æ–°èåª’é«” (News)", "è«–å£‡èˆ‡éƒ¨è½æ ¼ (Web/Blogs)", "Reddit è¨è«–å€", "Pinterest éˆæ„Ÿ"], default=["æ–°èåª’é«” (News)"])
    st.markdown("---")

    if st.button("ğŸš€ é–‹å§‹æœå°‹", type="primary"):
        if search_kw:
            keywords_list = [k.strip() for k in search_kw.split(",") if k.strip()]
            st.session_state.search_results = pd.DataFrame()
            
            # æ¨¡å¼ A
            if "å€‹åˆ¥åˆ†é–‹æœ" in search_logic:
                all_frames = []
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i, kw in enumerate(keywords_list):
                    status_text.text(f"æ­£åœ¨æœå°‹: {kw} ...")
                    df = run_hybrid_search(kw, location, search_scope, time_range)
                    if not df.empty:
                        df.insert(1, "Keyword", kw)
                        all_frames.append(df)
                    progress_bar.progress((i + 1) / len(keywords_list))
                    time.sleep(0.5)
                if all_frames:
                    st.session_state.search_results = pd.concat(all_frames).drop_duplicates(subset=['Link'])
                progress_bar.empty()
                status_text.empty()
            
            # æ¨¡å¼ B
            elif "è¯é›†æœå°‹" in search_logic:
                combined_query = " OR ".join([f"({k})" for k in keywords_list])
                with st.spinner(f"æ­£åœ¨åŸ·è¡Œè¯é›†: {combined_query}"):
                    df = run_hybrid_search(combined_query, location, search_scope, time_range)
                    if not df.empty:
                        df.insert(1, "Keyword", "è¯é›†çµæœ")
                        st.session_state.search_results = df
            
            # æ¨¡å¼ C
            elif "äº¤é›†æœå°‹" in search_logic:
                combined_query = " AND ".join([f"({k})" for k in keywords_list])
                with st.spinner(f"æ­£åœ¨åŸ·è¡Œäº¤é›†: {combined_query}"):
                    df = run_hybrid_search(combined_query, location, search_scope, time_range)
                    if not df.empty:
                        df.insert(1, "Keyword", "äº¤é›†çµæœ")
                        st.session_state.search_results = df

    if not st.session_state.search_results.empty:
        st.divider()
        st.markdown(f"### ğŸ“‹ æœå°‹çµæœ ({len(st.session_state.search_results)} ç­†)")
        target_folder = st.selectbox("ğŸ“¥ å­˜å…¥è³‡æ–™å¤¾:", st.session_state.folder_list)
        
        edited_df = st.data_editor(
            st.session_state.search_results,
            column_config={
                "Select": st.column_config.CheckboxColumn("æ”¶è—", width="small"),
                "Keyword": st.column_config.TextColumn("é—œéµå­—", width="small"),
                "Link": st.column_config.LinkColumn("é€£çµ", display_text="Go", width="small"),
                "Type": st.column_config.TextColumn("ä¾†æº", width="small"),
            },
            use_container_width=True,
            hide_index=True,
            key="search_editor"
        )
        
        if st.button(f"â¬‡ï¸ åŠ å…¥ã€Œ{target_folder}ã€"):
            selected_rows = edited_df[edited_df['Select'] == True].copy()
            if not selected_rows.empty:
                selected_rows['Folder'] = target_folder
                to_add = selected_rows.drop(columns=['Select'])
                st.session_state.favorites = pd.concat([st.session_state.favorites, to_add]).drop_duplicates(subset=['Link'])
                st.success(f"å·²å­˜å…¥ {target_folder}ï¼")
            else:
                st.warning("è«‹å…ˆå‹¾é¸è³‡æ–™ï¼")
    elif search_kw and st.session_state.search_results.empty:
        st.warning("æœªæ‰¾åˆ°è³‡æ–™ã€‚")

# === PAGE 2: è¶¨å‹¢åˆ†æ ===
elif page == "ğŸ“ˆ è¶¨å‹¢åˆ†æå„€":
    st.title("ğŸ“ˆ Google è¶¨å‹¢åˆ†æå„€")
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1: trend_input = st.text_input("è¼¸å…¥é—œéµå­— (å¯å¤šå€‹ï¼Œé€—è™Ÿåˆ†éš”)", "Fotile, Robam, Pacific")
    with col2: trend_geo = st.selectbox("åœ°å€", ["US", "CA", "HK"])
    with col3: trend_time = st.selectbox("æ™‚é–“", ["today 12-m", "today 1-m", "today 5-y"])
    
    if st.button("ğŸ“Š åˆ†æè¶¨å‹¢", type="primary"):
        kw_list = [k.strip() for k in trend_input.split(",") if k.strip()]
        if kw_list:
            with st.spinner(f"æ­£åœ¨åˆ†æ {kw_list} ..."):
                trend_df, related_df = fetch_trends_data(kw_list, trend_geo, trend_time)
                if not trend_df.empty:
                    st.line_chart(trend_df)
                    if not related_df.empty:
                        st.subheader("ğŸ’¡ ç›¸é—œæœå°‹")
                        st.dataframe(related_df, use_container_width=True)
                else:
                    st.warning("æš«æ™‚ç„¡æ³•ç²å–æ•¸æ“š (Rate Limit)ã€‚")
                    st.link_button("ğŸ‘‰ å‰å¾€ Google Trends å®˜ç¶²", f"https://trends.google.com/trends/explore?date={trend_time.replace(' ', '%20')}&geo={trend_geo}&q={','.join(kw_list)}")

# === PAGE 3: æ¯”åƒ¹ä¸­å¿ƒ ===
elif page == "ğŸ’° ç«¶å“æ¯”åƒ¹ä¸­å¿ƒ":
    st.title("ğŸ’° ç«¶å“æ¯”åƒ¹ä¸­å¿ƒ")
    st.subheader("ğŸš€ å®˜ç¶²å¿«é€Ÿå‚³é€é–€")
    col1, col2, col3, col4, col5, co16, co17 = st.columns(7)
    with col1: st.link_button("SAKURA USA", "https://sakura-usa.com/en-tw")
    with col2: st.link_button("SAKURA CA", "https://sakura-canada.com/")
    with col3: st.link_button("Fotile Store", "https://us.fotileglobal.com/collections/range-hoods")
    with col4: st.link_button("Robam Store", "https://robamliving.com/collections/range-hood")
    with col5: st.link_button("Pacific Store", "https://pacific-kitchen.com/shop/")
    with co16: st.link_button("Hauslane Store", "https://hauslane.com/collections/range-hoods")
    with co17: st.link_button("Le Kitchen", "https://www.lekitcheninc.com/")
    st.divider()
    st.subheader("ğŸ” ç‰¹å®šå‹è™ŸæŸ¥åƒ¹")
    col_a, col_b = st.columns([6, 1])
    with col_a: price_kw = st.text_input("è¼¸å…¥ç”¢å“å‹è™Ÿ", placeholder="ä¾‹å¦‚: JQG7501...")
    with col_b: price_region = st.selectbox("åœ°å€", ["US", "CA"])
    
    if st.button("ğŸ’° æœå°‹åƒ¹æ ¼"):
        if price_kw:
            with st.spinner(f"æ­£åœ¨æœå°‹ {price_kw}..."):
                price_df = fetch_web_search(price_kw, price_region, "éå»ä¸€å€‹æœˆ", platform_mode="shopping")
                if not price_df.empty:
                    st.dataframe(price_df[['Title', 'Source', 'Link']], column_config={"Link": st.column_config.LinkColumn("é»æ“ŠæŸ¥åƒ¹", display_text="Go ->")}, use_container_width=True, hide_index=True)
                else:
                    st.warning("è‡ªå‹•æœå°‹ç„¡çµæœã€‚")
                    encoded_kw = urllib.parse.quote(price_kw)
                    b1, b2 = st.columns(2)
                    with b1: st.link_button("ğŸ” Google Shopping", f"https://www.google.com/search?tbm=shop&q={encoded_kw}")
                    with b2: st.link_button("ğŸ“¦ Amazon", f"https://www.amazon.com/s?k={encoded_kw}")

# === PAGE 4: è³‡æ–™å¤¾ ===
elif page == "ğŸ“‚ ç«¶å“è³‡æ–™å¤¾":
    st.title("ğŸ“‚ ç«¶å“æƒ…å ±è³‡æ–™åº«")
    if st.session_state.favorites.empty:
        st.info("ç›®å‰ç„¡è³‡æ–™ã€‚")
    else:
        active_folders = st.session_state.folder_list
        tabs = st.tabs(active_folders)
        for i, folder_name in enumerate(active_folders):
            with tabs[i]:
                data = st.session_state.favorites[st.session_state.favorites['Folder'] == folder_name]
                if not data.empty:
                    st.write(f"ğŸ“ ({len(data)} ç­†)")
                    cols = ['Keyword', 'Type', 'Date', 'Title', 'Link'] if 'Keyword' in data.columns else ['Type', 'Date', 'Title', 'Link']
                    st.dataframe(data[cols], column_config={"Link": st.column_config.LinkColumn("Go"), "Date": st.column_config.DateColumn(format="YYYY-MM-DD")}, use_container_width=True, hide_index=True)
                    csv = data.to_csv(index=False).encode('utf-8-sig')
                    st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV", csv, f'{folder_name}.csv', 'text/csv')
                    if st.button("ğŸ—‘ï¸ æ¸…ç©º", key=f"del_{i}"):
                        st.session_state.favorites = st.session_state.favorites[st.session_state.favorites['Folder'] != folder_name]
                        st.rerun()
                else:
                    st.info("ç„¡è³‡æ–™")
